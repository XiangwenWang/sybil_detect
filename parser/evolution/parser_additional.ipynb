{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from shutil import copy2, rmtree\n",
    "from shutil import copyfile\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "904037"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('evolution2.json', orient='index')\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def get_itemID(index):\n",
    "    res = index.split('/')\n",
    "    if res[-1] == 'feedback' or res[-1] == 'return-policy':\n",
    "        return int(res[-2])\n",
    "    elif res[-1].find('.') >=0:\n",
    "        return int(res[-1].split('.')[0])\n",
    "    else:\n",
    "        return int(res[-1])\n",
    "\n",
    "data['itemID'] = map(get_itemID, list(data.index.values))\n",
    "\n",
    "data.to_json('evolution2.json', orient='index')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = '/media/intel/m2/evolution/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['image_location'] = root_path + data.date.astype(str) + '/' + data.img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[data.image_location.notnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = lambda x: '/'.join(x.split('/')[:-2])\n",
    "data['image_location'] = data.image_location.apply(f_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seller identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[data.seller.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_path = '/media/intel/m2/imgs/Evo'\n",
    "try:\n",
    "    rmtree(target_path)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.makedirs(target_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['seller_name'] = data.seller.apply(lambda x: os.path.join(target_path, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_count = []\n",
    "for index, row in data.iterrows():\n",
    "    img_f = row.image_location\n",
    "    if not os.path.isdir(img_f):\n",
    "        continue\n",
    "    for img_index in os.listdir(img_f):\n",
    "        if img_index == 'none':\n",
    "            continue\n",
    "        img_count.append(int(img_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 724552, 1: 106846, 2: 55465, 3: 32130, 4: 4976, 5: 1879, 6: 741, 7: 451, 8: 226, 9: 206, 10: 187, 32: 32, 29: 29, 30: 27, 21: 20, 11: 18, 22: 18, 31: 18, 34: 18, 28: 17, 23: 13, 24: 13, 25: 13, 26: 13, 19: 12, 20: 12, 27: 12, 33: 11, 12: 5, 13: 2, 14: 2, 17: 2, 15: 1, 16: 1, 18: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print Counter(img_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 6000 9000 12000 15000 18000 21000 24000 27000 30000 33000 36000 39000 42000 45000 48000 51000 54000 57000 60000 63000 66000 69000 72000 75000 78000 81000 84000 87000 90000 93000 96000 99000 102000 105000 108000 111000 114000 117000 120000 123000 126000 129000 132000 135000 138000 141000 144000 147000 150000 153000 156000 159000 162000 165000 168000 171000 174000 177000 180000 183000 186000 189000 192000 195000 198000 201000 204000 207000 210000 213000 216000 219000 222000 225000 228000 231000 234000 237000 240000 243000 246000 249000 252000 255000 258000 261000 264000 267000 270000 273000 276000 279000 282000 285000 288000 291000 294000 297000 300000 303000 306000 309000 312000 315000 318000 321000 324000 327000 330000 333000 336000 339000 342000 345000 348000 351000 354000 357000 360000 363000 366000 369000 372000 375000 378000 381000 384000 387000 390000 393000 396000 399000 402000 405000 408000 411000 414000 417000 420000 423000 426000 429000 432000 435000 438000 441000 444000 447000 450000 453000 456000 459000 462000 465000 468000 471000 474000 477000 480000 483000 486000 489000 492000 495000 498000 501000 504000 507000 510000 513000 516000 519000 522000 525000 528000 531000 534000 537000 540000 543000 546000 549000 552000 555000 558000 561000 564000 567000 570000 573000 576000 579000 582000 585000 588000 591000 594000 597000 600000 603000 606000 609000 612000 615000 618000 621000 624000 627000 630000 633000 636000 639000 642000 645000 648000 651000 654000 657000 660000 663000 666000 669000 672000 675000 678000 681000 684000 687000 690000 693000 696000 699000 702000 705000 708000 711000 714000 717000 720000 723000 726000 729000 732000 735000 738000 741000 744000 747000 750000 753000 756000 759000 762000 765000 768000 771000 774000\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for index, row in data.iterrows():\n",
    "    i += 1\n",
    "    if i % 3000 == 0:\n",
    "        print i,\n",
    "    img_f = row.image_location\n",
    "    if not os.path.isdir(img_f):\n",
    "        continue\n",
    "    for img_index in os.listdir(img_f):\n",
    "        if img_index == 'none':\n",
    "            continue\n",
    "        if os.path.isfile(os.path.join(img_f, img_index, 'large')):\n",
    "            oriname = 'large'\n",
    "        elif os.path.isfile(os.path.join(img_f, img_index, 'large.jpg')):\n",
    "            oriname = 'large.jpg'\n",
    "        else:\n",
    "            continue\n",
    "        img_path = os.path.join(img_f, img_index, oriname)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img.load()\n",
    "            img.close()\n",
    "        except IOError:\n",
    "            img.close()\n",
    "            continue       \n",
    "        if not os.path.isdir(row.seller_name):\n",
    "            os.makedirs(row.seller_name)\n",
    "        tar_file = os.path.join(row.seller_name, \"%d%2.2d.jpg\" % (row.itemID, int(img_index)))\n",
    "        copyfile(img_path, tar_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def md5sum(filename, blocksize=65536):\n",
    "    hash = hashlib.md5()\n",
    "    with open(filename, \"rb\") as f:\n",
    "        for block in iter(lambda: f.read(blocksize), b\"\"):\n",
    "            hash.update(block)\n",
    "    return hash.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root_dir = '/media/intel/m2/imgEvodedup'\n",
    "seller_name = [os.path.join(root_dir, x) for x in os.listdir(root_dir)]\n",
    "for seller_folder in set(seller_name):\n",
    "    filenames = map(lambda x: os.path.join(seller_folder, x), os.listdir(seller_folder))\n",
    "    md5value = {}\n",
    "    for filename in filenames:\n",
    "        md5curr = md5sum(filename)\n",
    "        if md5curr in md5value:\n",
    "            os.remove(filename)\n",
    "        else:\n",
    "            md5value[md5curr] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### category prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data3 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data3 = data3[data3.cat.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'Services', u'Fraud Related', u'Electronics', u'Digital Goods',\n",
       "       u'Guides &amp; Tutorials', u'Drugs', u'Counterfeits',\n",
       "       u'Miscellaneous', u'Erotica', u'Lab Supplies', u'Weapons',\n",
       "       u'Jewellery', u'Custom Listings', u'Drug Paraphernalia'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.cat.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_path = '/media/intel/m2/imgEvoCat'\n",
    "try:\n",
    "    os.mkdir(target_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "data3['cat_name'] = data3.cat.apply(lambda x: os.path.join(target_path, re.sub('[\\W_]+', '00', x)))\n",
    "\n",
    "for index, row in data3.iterrows():\n",
    "    img_f = row.image_location\n",
    "    if not os.path.isdir(img_f):\n",
    "        continue\n",
    "    for img_index in os.listdir(img_f):\n",
    "        if img_index == 'none':\n",
    "            continue\n",
    "        if os.path.isfile(os.path.join(img_f, img_index, 'large')):\n",
    "            oriname = 'large'\n",
    "        elif os.path.isfile(os.path.join(img_f, img_index, 'large.jpg')):\n",
    "            oriname = 'large.jpg'\n",
    "            '''\n",
    "            elif os.path.isfile(os.path.join(img_f, img_index, 'tiny')):\n",
    "                oriname = 'tiny'\n",
    "            elif os.path.isfile(os.path.join(img_f, img_index, 'tiny.jpg')):\n",
    "                oriname = 'tiny.jpg'\n",
    "            '''\n",
    "        else:\n",
    "            continue\n",
    "        img_path = os.path.join(img_f, img_index, oriname)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img.load()\n",
    "            img.close()\n",
    "        except IOError:\n",
    "            img.close()\n",
    "            continue        \n",
    "        if not os.path.isdir(row.cat_name):\n",
    "            os.makedirs(row.cat_name)\n",
    "        tar_file = os.path.join(row.cat_name, img_f.split('/')[-1] + 'xxxx' + img_index)\n",
    "        i = 0\n",
    "        while os.path.isfile(\"%sxxxx%d.jpg\" % (tar_file, i)):\n",
    "            i += 1\n",
    "        copyfile(img_path, \"%sxxxx%d.jpg\" % (tar_file, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def md5sum(filename, blocksize=65536):\n",
    "    hash = hashlib.md5()\n",
    "    with open(filename, \"rb\") as f:\n",
    "        for block in iter(lambda: f.read(blocksize), b\"\"):\n",
    "            hash.update(block)\n",
    "    return hash.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = '/media/intel/m2/imgEvoCat'\n",
    "seller_name = [os.path.join(root_dir, x) for x in os.listdir(root_dir)]\n",
    "for seller_folder in set(seller_name):\n",
    "    filenames = map(lambda x: os.path.join(seller_folder, x), os.listdir(seller_folder))\n",
    "    md5value = {}\n",
    "    for filename in filenames:\n",
    "        md5curr = md5sum(filename)\n",
    "        if md5curr in md5value:\n",
    "            os.remove(filename)\n",
    "        else:\n",
    "            md5value[md5curr] = filename"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
